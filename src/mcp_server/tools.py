"""
MCP å·¥å…·æ³¨å†Œæ¨¡å—

æ­¤æ¨¡å—å®šä¹‰å¹¶æ³¨å†Œè¡¨æ ¼è§£ææœåŠ¡å™¨çš„æ‰€æœ‰MCPå·¥å…·ã€‚
"""

import logging
from typing import Any
from pathlib import Path

from mcp.server import Server
from mcp.types import Tool, TextContent

from ..services.sheet_service import SheetService
from ..parsers.factory import ParserFactory
from ..converters.html_converter import HTMLConverter
from ..converters.json_converter import JSONConverter
from ..models.table_model import Sheet, Row, Cell, Style
from ..utils.performance import PerformanceOptimizer

logger = logging.getLogger(__name__)


def register_tools(server: Server) -> None:
    """å‘æœåŠ¡å™¨æ³¨å†Œæ‰€æœ‰MCPå·¥å…·ã€‚"""
    
    # åˆå§‹åŒ–æ ¸å¿ƒæœåŠ¡
    parser_factory = ParserFactory()
    html_converter = HTMLConverter()
    sheet_service = SheetService(parser_factory, html_converter)
    
    @server.list_tools()
    async def handle_list_tools() -> list[Tool]:
        # å·¥å…·æè¿°éƒ¨åˆ†ä¿æŒè‹±æ–‡
        return [
            Tool(
                name="parse_sheet_to_json",
                description="Parse a spreadsheet file and return structured JSON data for LLM analysis",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "Path to the spreadsheet file to parse"
                        }
                    },
                    "required": ["file_path"]
                }
            ),
            Tool(
                name="convert_json_to_html",
                description="Convert JSON spreadsheet data to a perfect HTML file with 95% style fidelity",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "json_data": {
                            "type": "object",
                            "description": "JSON data from parse_sheet_to_json"
                        },
                        "output_path": {
                            "type": "string",
                            "description": "Path where to save the HTML file"
                        }
                    },
                    "required": ["json_data", "output_path"]
                }
            ),
            Tool(
                name="convert_file_to_html",
                description="Smart direct conversion from file to HTML with intelligent processing strategy",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "Path to the spreadsheet file to convert"
                        },
                        "compact_mode": {
                            "type": "boolean",
                            "description": "Enable compact HTML mode for size optimization",
                            "default": True
                        }
                    },
                    "required": ["file_path"]
                }
            ),
            Tool(
                name="convert_file_to_html_file",
                description="Convert spreadsheet file directly to HTML file (large file friendly)",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "Path to the spreadsheet file to convert"
                        },
                        "output_path": {
                            "type": "string",
                            "description": "Path where to save the HTML file"
                        }
                    },
                    "required": ["file_path", "output_path"]
                }
            ),
            Tool(
                name="get_table_summary",
                description="Get a quick preview and summary of spreadsheet content",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "Path to the spreadsheet file to analyze"
                        }
                    },
                    "required": ["file_path"]
                }
            ),
            Tool(
                name="get_sheet_metadata",
                description="Get detailed metadata about the spreadsheet file",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "Path to the spreadsheet file to analyze"
                        }
                    },
                    "required": ["file_path"]
                }
            ),
            Tool(
                name="convert_file_to_html_paginated",
                description="Convert a large spreadsheet file to HTML with pagination support for better performance",
                inputSchema={
                    "type": "object",
                    "properties": {
                        "file_path": {
                            "type": "string",
                            "description": "Path to the spreadsheet file"
                        },
                        "output_dir": {
                            "type": "string",
                            "description": "Directory to save paginated HTML files"
                        },
                        "max_rows_per_page": {
                            "type": "integer",
                            "description": "Maximum number of rows per page (default: 1000)",
                            "default": 1000
                        },
                        "compact_mode": {
                            "type": "boolean",
                            "description": "Enable compact HTML mode for smaller file sizes (default: true)",
                            "default": True
                        }
                    },
                    "required": ["file_path", "output_dir"]
                }
            )
        ]
    
    @server.call_tool()
    async def handle_call_tool(name: str, arguments: dict[str, Any]) -> list[TextContent]:
        """å¤„ç†å·¥å…·è°ƒç”¨ã€‚"""
        try:
            if name == "parse_sheet_to_json":
                return await _handle_parse_sheet_to_json(arguments, sheet_service)
            elif name == "convert_json_to_html":
                return await _handle_convert_json_to_html(arguments, sheet_service)
            elif name == "convert_file_to_html":
                return await _handle_convert_file_to_html(arguments, sheet_service)
            elif name == "convert_file_to_html_file":
                return await _handle_convert_file_to_html_file(arguments, sheet_service)
            elif name == "get_table_summary":
                return await _handle_get_table_summary(arguments, sheet_service)
            elif name == "get_sheet_metadata":
                return await _handle_get_sheet_metadata(arguments, sheet_service)
            elif name == "convert_file_to_html_paginated":
                return await _handle_convert_file_to_html_paginated(arguments, sheet_service)
            else:
                raise ValueError(f"æœªçŸ¥å·¥å…·: {name}")
                
        except Exception as e:
            logger.error(f"å·¥å…· {name} å‡ºé”™: {e}")
            return [TextContent(
                type="text",
                text=f"é”™è¯¯: {str(e)}"
            )]


# å·¥å…·å¤„ç†å‡½æ•°
async def _handle_parse_sheet_to_json(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† parse_sheet_to_json å·¥å…·è°ƒç”¨ã€‚"""
    file_path = arguments.get("file_path")
    if not file_path:
        raise ValueError("å¿…é¡»æä¾› file_path")

    if not Path(file_path).exists():
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    try:
        # è§£ææ–‡ä»¶ä¸º Sheet å¯¹è±¡
        parser_factory = ParserFactory()
        parser = parser_factory.get_parser(file_path)
        sheet = parser.parse(file_path)

        # è½¬æ¢ä¸º JSON
        json_converter = JSONConverter()
        json_data = json_converter.convert(sheet)

        # è·å–å¤§å°ä¼°ç®—
        size_info = json_converter.estimate_json_size(sheet)

        # è¿”å›å¸¦å…ƒæ•°æ®çš„ JSON æ•°æ®
        import json
        json_string = json.dumps(json_data, indent=2, ensure_ascii=False)

        return [TextContent(
            type="text",
            text=f"JSON è½¬æ¢æˆåŠŸï¼\n\n"
                 f"å…ƒæ•°æ®:\n"
                 f"- è¡Œæ•°: {json_data['metadata']['rows']}\n"
                 f"- åˆ—æ•°: {json_data['metadata']['cols']}\n"
                 f"- å”¯ä¸€æ ·å¼æ•°: {len(json_data['styles'])}\n"
                 f"- JSON å­—ç¬¦æ•°: {size_info['total_characters']}\n"
                 f"- ä¼°ç®—å­—èŠ‚æ•°: {size_info['total_bytes']}\n\n"
                 f"JSON æ•°æ®:\n{json_string}"
        )]
    except Exception as e:
        raise RuntimeError(f"è§£æè¡¨æ ¼ä¸º JSON å¤±è´¥: {str(e)}")


async def _handle_convert_json_to_html(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† convert_json_to_html å·¥å…·è°ƒç”¨ã€‚"""
    json_data = arguments.get("json_data")
    output_path = arguments.get("output_path")

    if not json_data:
        raise ValueError("å¿…é¡»æä¾› json_data")
    if not output_path:
        raise ValueError("å¿…é¡»æä¾› output_path")

    try:
        # ä» JSON æ•°æ®é‡å»º Sheet å¯¹è±¡
        sheet = _json_to_sheet(json_data)

        # è½¬æ¢ä¸ºä¼˜åŒ–åçš„ HTML
        html_converter = HTMLConverter(compact_mode=True)
        html_content = html_converter.convert(sheet, optimize=True)

        # å†™å…¥æ–‡ä»¶
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(html_content, encoding='utf-8')

        # è·å–å¤§å°ä¿¡æ¯
        file_size = len(html_content)

        return [TextContent(
            type="text",
            text=f"HTML æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼\n\n"
                 f"è¾“å‡ºè·¯å¾„: {output_path}\n"
                 f"æ–‡ä»¶å­—ç¬¦æ•°: {file_size}\n"
                 f"å¤„ç†è¡Œæ•°: {len(sheet.rows)}\n"
                 f"ä¼˜åŒ–: å¯ç”¨ CSS ç±»å¤ç”¨\n\n"
                 f"HTML æ–‡ä»¶å·²ä¿å­˜ï¼Œæ ·å¼è¿˜åŸåº¦ 95%ï¼Œå¹¶å·²ä¼˜åŒ–ä½“ç§¯ã€‚"
        )]
    except Exception as e:
        raise RuntimeError(f"JSON è½¬ HTML å¤±è´¥: {str(e)}")


async def _handle_convert_file_to_html(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† convert_file_to_html å·¥å…·è°ƒç”¨ã€‚"""
    # åŸºäºç°æœ‰æœåŠ¡çš„åŸºç¡€å®ç°
    file_path = arguments.get("file_path")
    if not file_path:
        raise ValueError("å¿…é¡»æä¾› file_path")
    
    if not Path(file_path).exists():
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
    
    try:
        html_content = service.convert_to_html(file_path)
        return [TextContent(
            type="text",
            text=f"HTML è½¬æ¢å®Œæˆã€‚å†…å®¹é•¿åº¦: {len(html_content)} å­—ç¬¦ã€‚\n\n{html_content}"
        )]
    except Exception as e:
        raise RuntimeError(f"æ–‡ä»¶è½¬ HTML å¤±è´¥: {str(e)}")


async def _handle_convert_file_to_html_file(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† convert_file_to_html_file å·¥å…·è°ƒç”¨ã€‚"""
    file_path = arguments.get("file_path")
    output_path = arguments.get("output_path")

    if not file_path:
        raise ValueError("å¿…é¡»æä¾› file_path")
    if not output_path:
        raise ValueError("å¿…é¡»æä¾› output_path")

    if not Path(file_path).exists():
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    try:
        # è§£ææ–‡ä»¶
        parser_factory = ParserFactory()
        parser = parser_factory.get_parser(file_path)
        sheet = parser.parse(file_path)

        # è½¬æ¢ä¸ºä¼˜åŒ–åçš„ HTML
        html_converter = HTMLConverter(compact_mode=True)
        html_content = html_converter.convert(sheet, optimize=True)

        # å†™å…¥æ–‡ä»¶
        output_file = Path(output_path)
        output_file.parent.mkdir(parents=True, exist_ok=True)
        output_file.write_text(html_content, encoding='utf-8')

        # è·å–ç»Ÿè®¡ä¿¡æ¯
        file_size = len(html_content)
        size_info = html_converter.estimate_size_reduction(sheet)

        return [TextContent(
            type="text",
            text=f"HTML æ–‡ä»¶è½¬æ¢æˆåŠŸï¼\n\n"
                 f"è¾“å…¥æ–‡ä»¶: {file_path}\n"
                 f"è¾“å‡ºæ–‡ä»¶: {output_path}\n"
                 f"æ–‡ä»¶å­—ç¬¦æ•°: {file_size}\n"
                 f"è¡Œæ•°: {len(sheet.rows)}\n"
                 f"ä¼˜åŒ–ç‡: {size_info['reduction_percentage']:.1f}%\n"
                 f"æ ·å¼è¿˜åŸåº¦: 95%\n\n"
                 f"HTML æ–‡ä»¶å·²ä¿å­˜ï¼Œå…·å¤‡ä¸“ä¸šæ ·å¼ä¸ä¼˜åŒ–æ€§èƒ½ã€‚"
        )]
    except Exception as e:
        raise RuntimeError(f"æ–‡ä»¶è½¬ HTML æ–‡ä»¶å¤±è´¥: {str(e)}")


async def _handle_get_table_summary(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† get_table_summary å·¥å…·è°ƒç”¨ã€‚"""
    file_path = arguments.get("file_path")
    if not file_path:
        raise ValueError("å¿…é¡»æä¾› file_path")

    if not Path(file_path).exists():
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    try:
        # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
        optimizer = PerformanceOptimizer()
        optimizer.start_timing()

        # è§£ææ–‡ä»¶
        parser_factory = ParserFactory()
        parser = parser_factory.get_parser(file_path)
        sheet = parser.parse(file_path)

        # åˆ†ææ€§èƒ½æŒ‡æ ‡
        metrics = optimizer.analyze_sheet_performance(sheet)

        # ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
        total_rows = metrics.rows
        total_cols = metrics.cols

        # ç»Ÿè®¡è¿›é˜¶åŠŸèƒ½ä½¿ç”¨æƒ…å†µ
        hyperlink_cells = 0
        comment_cells = 0
        for row in sheet.rows:
            for cell in row.cells:
                if cell.style:
                    if cell.style.hyperlink:
                        hyperlink_cells += 1
                    if cell.style.comment:
                        comment_cells += 1

        # è·å–å‰5è¡Œæ ·ä¾‹æ•°æ®
        sample_data = []
        for i, row in enumerate(sheet.rows[:5]):
            row_data = []
            for j, cell in enumerate(row.cells[:5]):  # å‰5åˆ—
                value = str(cell.value) if cell.value is not None else ""
                row_data.append(value[:20] + "..." if len(value) > 20 else value)
            sample_data.append(f"ç¬¬{i+1}è¡Œ: {' | '.join(row_data)}")

        # è·å–æ€§èƒ½å»ºè®®
        recommendation = optimizer.get_recommendation_message(metrics.recommendation, metrics)

        # è®¡ç®—æ€»å•å…ƒæ ¼æ•°
        total_cells = metrics.total_cells

        return [TextContent(
            type="text",
            text=f"è¡¨æ ¼æ‘˜è¦: {Path(file_path).name}\n\n"
                 f"ğŸ“Š åŸºæœ¬ç»Ÿè®¡:\n"
                 f"- è¡¨å: {sheet.name}\n"
                 f"- å°ºå¯¸: {total_rows} è¡Œ Ã— {total_cols} åˆ—\n"
                 f"- æ€»å•å…ƒæ ¼: {total_cells:,}\n"
                 f"- éç©ºå•å…ƒæ ¼: {metrics.non_empty_cells:,}\n"
                 f"- æœ‰æ ·å¼å•å…ƒæ ¼: {metrics.styled_cells:,}\n"
                 f"- åˆå¹¶å•å…ƒæ ¼: {len(sheet.merged_cells) if sheet.merged_cells else 0}\n\n"
                 f"ğŸš€ è¿›é˜¶åŠŸèƒ½:\n"
                 f"- è¶…é“¾æ¥å•å…ƒæ ¼: {hyperlink_cells:,}\n"
                 f"- æ³¨é‡Šå•å…ƒæ ¼: {comment_cells:,}\n\n"
                 f"ğŸ“‹ å‰5è¡Œæ ·ä¾‹:\n" + "\n".join(sample_data) + "\n\n"
                 f"ğŸ’¡ å¤„ç†å»ºè®®:\n{recommendation}\n\n"
                 f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:\n"
                 f"- ä¼°ç®—HTMLå¤§å°: ~{metrics.estimated_html_size:,} å­—ç¬¦\n"
                 f"- ä¼°ç®—JSONå¤§å°: ~{metrics.estimated_json_size:,} å­—ç¬¦\n"
                 f"- è§£æè€—æ—¶: {metrics.processing_time:.2f} ç§’"
        )]
    except Exception as e:
        raise RuntimeError(f"ç”Ÿæˆè¡¨æ ¼æ‘˜è¦å¤±è´¥: {str(e)}")


async def _handle_get_sheet_metadata(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† get_sheet_metadata å·¥å…·è°ƒç”¨ã€‚"""
    file_path = arguments.get("file_path")
    if not file_path:
        raise ValueError("å¿…é¡»æä¾› file_path")

    if not Path(file_path).exists():
        raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")

    try:
        # è·å–æ–‡ä»¶ä¿¡æ¯
        file_info = Path(file_path)
        file_size = file_info.stat().st_size
        file_ext = file_info.suffix.lower()

        # è§£ææ–‡ä»¶
        parser_factory = ParserFactory()
        parser = parser_factory.get_parser(file_path)
        sheet = parser.parse(file_path)

        # æ ·å¼åˆ†æ
        unique_styles = set()
        font_families = set()
        colors = set()

        for row in sheet.rows:
            for cell in row.cells:
                if cell.style:
                    # æ ·å¼ç­¾å
                    style_sig = f"{cell.style.bold}_{cell.style.italic}_{cell.style.font_color}_{cell.style.background_color}"
                    unique_styles.add(style_sig)

                    if cell.style.font_name:
                        font_families.add(cell.style.font_name)
                    if cell.style.font_color:
                        colors.add(cell.style.font_color)
                    if cell.style.background_color:
                        colors.add(cell.style.background_color)

        # æ•°æ®ç±»å‹åˆ†æ
        data_types = {"text": 0, "number": 0, "empty": 0}
        for row in sheet.rows:
            for cell in row.cells:
                if cell.value is None or str(cell.value).strip() == "":
                    data_types["empty"] += 1
                elif isinstance(cell.value, (int, float)):
                    data_types["number"] += 1
                else:
                    data_types["text"] += 1

        # ç”Ÿæˆ JSON å’Œ HTML å¤§å°ä¼°ç®—
        json_converter = JSONConverter()
        json_size = json_converter.estimate_json_size(sheet)

        html_converter = HTMLConverter(compact_mode=True)
        html_size = html_converter.estimate_size_reduction(sheet)

        return [TextContent(
            type="text",
            text=f"è¡¨æ ¼å…ƒæ•°æ®: {file_info.name}\n\n"
                 f"ğŸ“ æ–‡ä»¶ä¿¡æ¯:\n"
                 f"- è·¯å¾„: {file_path}\n"
                 f"- æ–‡ä»¶å¤§å°: {file_size:,} å­—èŠ‚\n"
                 f"- æ–‡ä»¶æ ¼å¼: {file_ext.upper()}\n"
                 f"- è¡¨å: {sheet.name}\n\n"
                 f"ğŸ“Š ç»“æ„:\n"
                 f"- å°ºå¯¸: {len(sheet.rows)} è¡Œ Ã— {len(sheet.rows[0].cells) if sheet.rows else 0} åˆ—\n"
                 f"- æ€»å•å…ƒæ ¼: {len(sheet.rows) * (len(sheet.rows[0].cells) if sheet.rows else 0):,}\n"
                 f"- åˆå¹¶å•å…ƒæ ¼: {len(sheet.merged_cells) if sheet.merged_cells else 0}\n\n"
                 f"ğŸ¨ æ ·å¼:\n"
                 f"- å”¯ä¸€æ ·å¼æ•°: {len(unique_styles)}\n"
                 f"- å­—ä½“æ—: {len(font_families)} ({', '.join(list(font_families)[:3])}{'...' if len(font_families) > 3 else ''})\n"
                 f"- ä½¿ç”¨é¢œè‰²æ•°: {len(colors)}\n\n"
                 f"ğŸ“ˆ æ•°æ®åˆ†æ:\n"
                 f"- æ–‡æœ¬å•å…ƒæ ¼: {data_types['text']:,}\n"
                 f"- æ•°å­—å•å…ƒæ ¼: {data_types['number']:,}\n"
                 f"- ç©ºå•å…ƒæ ¼: {data_types['empty']:,}\n\n"
                 f"ğŸ’¾ è¾“å‡ºä¼°ç®—:\n"
                 f"- JSON å­—ç¬¦æ•°: {json_size['total_characters']:,}\n"
                 f"- HTML åŸå§‹å¤§å°: {html_size['original_size']:,}\n"
                 f"- HTML ä¼˜åŒ–åå¤§å°: {html_size['optimized_size']:,}\n"
                 f"- ä¼˜åŒ–èŠ‚çœ: {html_size['reduction_percentage']:.1f}%"
        )]
    except Exception as e:
        raise RuntimeError(f"è·å–è¡¨æ ¼å…ƒæ•°æ®å¤±è´¥: {str(e)}")


def _json_to_sheet(json_data: dict[str, Any]) -> Sheet:
    """
    å°†JSONæ•°æ®è½¬æ¢å›Sheetå¯¹è±¡ã€‚

    å‚æ•°:
        json_data: æ¥è‡ª parse_sheet_to_json çš„JSONæ•°æ®

    è¿”å›:
        é‡æ„çš„Sheetå¯¹è±¡
    """
    # è¿™é‡Œå·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ Sheet, Row, Cell, Style

    # æå–å…ƒæ•°æ®
    metadata = json_data.get('metadata', {})
    sheet_name = metadata.get('name', 'Untitled')

    # æå–æ ·å¼
    styles_dict = json_data.get('styles', {})

    # é‡å»ºè¡Œ
    rows = []
    for row_data in json_data.get('data', []):
        cells = []
        for cell_data in row_data.get('cells', []):
            # é‡å»ºå•å…ƒæ ¼å€¼
            value = cell_data.get('value')

            # é‡å»ºæ ·å¼
            style = None
            style_id = cell_data.get('style_id')
            if style_id and style_id in styles_dict:
                style_data = styles_dict[style_id]
                style = Style(
                    bold=style_data.get('bold', False),
                    italic=style_data.get('italic', False),
                    underline=style_data.get('underline', False),
                    font_color=style_data.get('font_color', '#000000'),
                    background_color=style_data.get('background_color', '#FFFFFF'),
                    text_align=style_data.get('text_align', 'left'),
                    vertical_align=style_data.get('vertical_align', 'top'),
                    font_size=style_data.get('font_size'),
                    font_name=style_data.get('font_name'),
                    border_top=style_data.get('border_top', ''),
                    border_bottom=style_data.get('border_bottom', ''),
                    border_left=style_data.get('border_left', ''),
                    border_right=style_data.get('border_right', ''),
                    border_color=style_data.get('border_color', '#000000'),
                    wrap_text=style_data.get('wrap_text', False),
                    number_format=style_data.get('number_format', '')
                )

            # åˆ›å»ºå•å…ƒæ ¼
            cell = Cell(value=value, style=style)
            cells.append(cell)

        rows.append(Row(cells=cells))

    # åˆ›å»º Sheet
    merged_cells = json_data.get('merged_cells', [])
    return Sheet(name=sheet_name, rows=rows, merged_cells=merged_cells)


async def _handle_convert_file_to_html_paginated(arguments: dict[str, Any], service: SheetService) -> list[TextContent]:
    """å¤„ç† convert_file_to_html_paginated å·¥å…·è°ƒç”¨ã€‚"""
    file_path = arguments.get("file_path")
    output_dir = arguments.get("output_dir")
    max_rows_per_page = arguments.get("max_rows_per_page", 1000)
    compact_mode = arguments.get("compact_mode", True)

    if not file_path:
        raise ValueError("ç¼ºå°‘å¿…éœ€å‚æ•°: file_path")
    if not output_dir:
        raise ValueError("ç¼ºå°‘å¿…éœ€å‚æ•°: output_dir")

    try:
        import os

        # åˆå§‹åŒ–æ€§èƒ½ä¼˜åŒ–å™¨
        optimizer = PerformanceOptimizer()
        optimizer.start_timing()

        # è§£ææ–‡ä»¶
        parser_factory = ParserFactory()
        parser = parser_factory.get_parser(file_path)
        sheet = parser.parse(file_path)

        # åˆ†ææ€§èƒ½æŒ‡æ ‡
        metrics = optimizer.analyze_sheet_performance(sheet)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ†é¡µ
        if not optimizer.should_use_pagination(metrics):
            return [TextContent(
                type="text",
                text=f"æ–‡ä»¶ä¸éœ€è¦åˆ†é¡µå¤„ç†ã€‚å»ºè®®ä½¿ç”¨ convert_file_to_html_file å·¥å…·ã€‚\n"
                     f"æ–‡ä»¶å¤§å°: {metrics.total_cells:,} ä¸ªå•å…ƒæ ¼\n"
                     f"å¤„ç†å»ºè®®: {optimizer.get_recommendation_message(metrics.recommendation, metrics)}"
            )]

        # è®¡ç®—åˆ†é¡µå‚æ•°
        pagination = optimizer.calculate_pagination_params(sheet, max_rows_per_page)

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)

        # åˆ›å»ºHTMLè½¬æ¢å™¨
        html_converter = HTMLConverter()

        # ç”Ÿæˆåˆ†é¡µæ–‡ä»¶
        generated_files = []
        base_filename = Path(file_path).stem

        for page_info in pagination["pages"]:
            # åˆ›å»ºå½“å‰é¡µçš„Sheetå¯¹è±¡
            page_rows = sheet.rows[page_info["start_row"]:page_info["end_row"]]
            page_sheet = Sheet(
                name=f"{sheet.name} - ç¬¬{page_info['page_number']}é¡µ",
                rows=page_rows,
                merged_cells=[]  # åˆ†é¡µæ—¶æš‚ä¸å¤„ç†åˆå¹¶å•å…ƒæ ¼
            )

            # è½¬æ¢ä¸ºHTML
            html_content = html_converter.convert(page_sheet)

            # ä¿å­˜æ–‡ä»¶
            page_filename = f"{base_filename}_page_{page_info['page_number']:03d}.html"
            page_file_path = output_path / page_filename

            with open(page_file_path, 'w', encoding='utf-8') as f:
                f.write(html_content)

            generated_files.append(str(page_file_path))

        # ç”Ÿæˆç´¢å¼•æ–‡ä»¶
        index_content = f"""<!DOCTYPE html>
<html>
<head>
    <title>{sheet.name} - åˆ†é¡µç´¢å¼•</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .summary {{ background: #f5f5f5; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
        .page-list {{ list-style-type: none; padding: 0; }}
        .page-list li {{ margin: 10px 0; }}
        .page-list a {{ text-decoration: none; color: #0066cc; }}
        .page-list a:hover {{ text-decoration: underline; }}
        .stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 10px; }}
        .stat {{ background: white; padding: 10px; border-radius: 3px; border-left: 4px solid #0066cc; }}
    </style>
</head>
<body>
    <h1>{sheet.name} - åˆ†é¡µç´¢å¼•</h1>

    <div class="summary">
        <h2>ğŸ“Š æ–‡ä»¶ç»Ÿè®¡</h2>
        <div class="stats">
            <div class="stat">
                <strong>æ€»è¡Œæ•°:</strong> {metrics.rows:,}
            </div>
            <div class="stat">
                <strong>æ€»åˆ—æ•°:</strong> {metrics.cols:,}
            </div>
            <div class="stat">
                <strong>æ€»å•å…ƒæ ¼:</strong> {metrics.total_cells:,}
            </div>
            <div class="stat">
                <strong>éç©ºå•å…ƒæ ¼:</strong> {metrics.non_empty_cells:,}
            </div>
            <div class="stat">
                <strong>åˆ†é¡µæ•°é‡:</strong> {pagination['total_pages']}
            </div>
            <div class="stat">
                <strong>æ¯é¡µè¡Œæ•°:</strong> {max_rows_per_page:,}
            </div>
        </div>
    </div>

    <h2>ğŸ“„ åˆ†é¡µåˆ—è¡¨</h2>
    <ul class="page-list">
"""

        for page_info in pagination["pages"]:
            page_filename = f"{base_filename}_page_{page_info['page_number']:03d}.html"
            index_content += f"""        <li>
            <a href="{page_filename}">
                ç¬¬ {page_info['page_number']} é¡µ
                (è¡Œ {page_info['start_row'] + 1:,} - {page_info['end_row']:,},
                å…± {page_info['row_count']:,} è¡Œ)
            </a>
        </li>
"""

        index_content += """    </ul>
</body>
</html>"""

        # ä¿å­˜ç´¢å¼•æ–‡ä»¶
        index_file_path = output_path / f"{base_filename}_index.html"
        with open(index_file_path, 'w', encoding='utf-8') as f:
            f.write(index_content)

        generated_files.insert(0, str(index_file_path))

        return [TextContent(
            type="text",
            text=f"âœ… åˆ†é¡µè½¬æ¢å®Œæˆ!\n\n"
                 f"ğŸ“Š å¤„ç†ç»Ÿè®¡:\n"
                 f"- åŸæ–‡ä»¶: {Path(file_path).name}\n"
                 f"- æ€»è¡Œæ•°: {metrics.rows:,}\n"
                 f"- æ€»é¡µæ•°: {pagination['total_pages']}\n"
                 f"- æ¯é¡µè¡Œæ•°: {max_rows_per_page:,}\n"
                 f"- å¤„ç†æ—¶é—´: {metrics.processing_time:.2f} ç§’\n\n"
                 f"ğŸ“ ç”Ÿæˆæ–‡ä»¶:\n" + "\n".join(f"- {Path(f).name}" for f in generated_files) + "\n\n"
                 f"ğŸ’¡ ä½¿ç”¨å»ºè®®:\n"
                 f"- æ‰“å¼€ {base_filename}_index.html æŸ¥çœ‹åˆ†é¡µç´¢å¼•\n"
                 f"- æ¯ä¸ªåˆ†é¡µæ–‡ä»¶åŒ…å« {max_rows_per_page:,} è¡Œæ•°æ®\n"
                 f"- æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}"
        )]

    except Exception as e:
        raise RuntimeError(f"åˆ†é¡µè½¬æ¢å¤±è´¥: {str(e)}")
